---
title: "project2 Tutorial"
author: "Yuchi Hsieh"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{project2 Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


# Introduction
It is a tutorial for the project2 in Stat302. It includes four functions and their tutorials which are `my_t.test`, `my_lm`, `my_knn_cv`, `my_rf_cv`.

## Installation

To download the project2 package, use the code below.

``` {r, eval = FALSE}
# install.packages("devtools")
devtools::install_github("yuchiiii/project2")
library(project2)
```

```{r setup, echo=FALSE}
library(project2)
library(ggplot2)
```

# Tutorials 

## my_t.test

```{r}
data <- my_gapminder$lifeExp
my_t.test(data, "two.sided", 60)
my_t.test(data, "less", 60)
my_t.test(data, "greater", 60)
```
For the first test, the alternative hypothesis is mu doesn't equal to 60. The p-value of the first test is 0.0932 which is greater than the cut-off. Thus, we cannot reject that the true mean of life expectancy equals to 60. 

For the second test, the alternative hypothesis is that mu is less than 60. The p-value of the second test is 0.046 which is smaller than 0.05. We can reject the null hypothesis in favor of the alternative hypothesis, which states that the true mean of life expectancy is less than 60.

For the third test, the alternative hypothesis is that mu is greater than 60. The p-value of this t-test is 0.953 which is much larger than the cut-off. Thus, we cannot reject that the true mean of life expectancy is equal to 60. 

## my_lm

```{r, fig.width=7}
# Demonstrate a regression.
test_data <- my_gapminder
test_formula <- lifeExp ~ gdpPercap + continent
mylm_result <- my_lm(test_formula, test_data)
mylm_result

# Use ggplot2 to plot the Actual vs. Fitted values
my_coef <- mylm_result$Estimate
my_matrix <- model.matrix(lifeExp ~ gdpPercap + continent, data = my_gapminder)
y_hat <- my_matrix %*% as.matrix(my_coef)
my_df <- data.frame("actual" = my_gapminder$lifeExp, "fitted" = y_hat, "continent" = my_gapminder$continent)
ggplot(my_df, aes(x = fitted, y = actual)) +
  geom_point(aes(colour = continent)) +
  geom_abline(slope = 1, intercept = 0, col = "red", lty = 2) + 
  theme_bw(base_size = 15) +
  labs(x = "Fitted values", y = "Actual values", title = "Actual vs. Fitted") +
  theme(plot.title = element_text(hjust = 0.5)) 
```


The `gdpPercap` coefficient means that there is a 4.4527e-4 average change in the life expectancy for every unit change in `gdpPercap`. (If all other coefficients are held constant). 

The hypothesis testing for `gdpPercap` coefficient will be: 

H0: beta = 0

H1: beta != 0

The p-value for `gdpPercap` coefficient is 8.55e-73 which is much smaller than 0.05 so we can reject the null hyphthesis in favor of the alternative hypothesis. Thus, there is a statistically significant relationship between `gdpPercap` and `lifeExp`.

From the graph, we can see that the data of different continents cluster together. Although there is a linear pattern across continents, it is not very obvious. For Africa and Asia, many data is in a vertical relationship, which shows that the model is not accurate. Thus, it might not be a good idea to incorporate the continents into the linear model. 

## my_knn_cv

```{r}
# Predict output class species using covariates.
# # Clean the dataset.
penguins_df <- my_penguins
penguins_df <- na.omit(penguins_df)
penguins_df$species <- as.character(penguins_df$species)

# Vectors to store the training misclassification rate and cv misclassification rate.
train_rate <- vector()
cv_rate <- vector()

# Apply the function to the penguins data.
for (i in 1:10) {
  knn_result <- my_knn_cv(penguins_df, penguins_df$species, i, 5)
  cv_rate[i] <- knn_result$cv_err
  result <- knn_result$class
  train_err <- sum(knn_result$class != penguins_df$species) /    length(penguins_df$species)
  train_rate[i] <- train_err
}
```

Based on the training misclassification rates, I would choose k_nn = 1. Based on the CV misclassification rates, I would choose k_nn = 5.

I would choose k_nn = 5 since k_nn = 1 will cause over fitting which is not suitable for prediction. Low training error doesn't mean the model is better since we want the model has a low error on the prediction.

Cross-validation splits data into k parts and choose one part as test data while the remaining parts are used as training for prediction. This is useful since we can train the model many times to get the mean error rate, which is more accurate than using the whole dataset as the training data.

## my_rf_cv

```{r}
iter <- c(2, 5, 10)
rf_result <- data.frame(matrix(ncol = 3, nrow = 30))
for (i in 1:3) {
  k <- iter[i]
  for (j in 1:30) {
    ans <- my_rf_cv(k)
    rf_result[j,i] <- ans
  }
}
colnames(rf_result) <- c("k = 2", "k = 5", "k = 10")
boxplot(rf_result, xlab = "k", ylab = "CV estimated MSE")
result_table <- data.frame(matrix(ncol = 2, nrow = 3))
result_table[1,1] <- mean(rf_result[, 1])
result_table[2,1] <- mean(rf_result[, 2])
result_table[3,1] <- mean(rf_result[, 3])
result_table[1,2] <- sd(rf_result[, 1])
result_table[2,2] <- sd(rf_result[, 2])
result_table[3,2] <- sd(rf_result[, 3])
colnames(result_table) <- c("mean", "sd")
rownames(result_table) <- c("k = 2", "k = 5", "k = 10")
result_table
```

When k = 5, it has the smallest mean. As k increases, the standard deviation becomes bigger and bigger. I think it's because when k is greater, the data is split into more trees causing larger standard deviations across trees.





